{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJwMsPMYekjc",
        "outputId": "3a8c7595-1526-478b-a35d-22c422bc2773"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stylegan2-pytorch'...\n",
            "remote: Enumerating objects: 395, done.\u001b[K\n",
            "remote: Total 395 (delta 0), reused 0 (delta 0), pack-reused 395 (from 1)\u001b[K\n",
            "Receiving objects: 100% (395/395), 122.51 MiB | 15.56 MiB/s, done.\n",
            "Resolving deltas: 100% (205/205), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/rosinality/stylegan2-pytorch.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buXb126GajzB",
        "outputId": "e0e5a610-9e46-4b9f-a862-91c6f5b26050"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stylegan2-pytorch\n"
          ]
        }
      ],
      "source": [
        "cd stylegan2-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOQYG0ZzieHM",
        "outputId": "a8ff6f5d-09f4-4509-c85a-5cc356794467"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niEUaH6miEMN",
        "outputId": "d2c6512a-0a17-479b-e04e-3410637f0d87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Ninja\n",
            "  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
            "Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/422.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Ninja\n",
            "Successfully installed Ninja-1.11.1.3\n"
          ]
        }
      ],
      "source": [
        "!pip install Ninja"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Репозиторий StyleGAN-2 использует более старую версию библиотеки skimage, поэтому нам необходимо сделать небольшую корректировку файла с lpips лоссом.\n",
        "file_path = \"/content/stylegan2-pytorch/lpips/__init__.py\"\n",
        "\n",
        "# Откроем файл и прочитаем его содержимое\n",
        "with open(file_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Заменим нужную строку\n",
        "with open(file_path, 'w') as file:\n",
        "    for line in lines:\n",
        "        # Если в строке есть \"compare_ssim\", заменим на \"structural_similarity\"\n",
        "        if \"from skimage.measure import compare_ssim\" in line:\n",
        "            file.write(\"from skimage.metrics import structural_similarity\\n\")\n",
        "        else:\n",
        "            file.write(line)\n",
        "\n",
        "print(\"Замена выполнена успешно!\")\n",
        "\n",
        "import lpips  # Библиотека для вычисления perceptual loss\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2R3vsa8QWa9",
        "outputId": "5a90af59-a26f-49bb-abd3-4613eb13c440"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Замена выполнена успешно!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка модели StyleGAN-2\n",
        "!gdown 1EM87UquaoQmk17Q8d5kYIAHqu0dkYqdT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsG9j2-cQhL_",
        "outputId": "4a9bb45b-e8d5-49be-afb9-32d34aafa85a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1EM87UquaoQmk17Q8d5kYIAHqu0dkYqdT\n",
            "From (redirected): https://drive.google.com/uc?id=1EM87UquaoQmk17Q8d5kYIAHqu0dkYqdT&confirm=t&uuid=a39750ef-36f5-4e95-8a65-254d16353624\n",
            "To: /content/stylegan2-pytorch/stylegan2-ffhq-config-f.pt\n",
            "100% 381M/381M [00:11<00:00, 32.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCWCu8WbQsNL",
        "outputId": "151431cc-3fbe-47e4-d61f-7745dd9a7573"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Скачаем стартовое изображение\n",
        "!wget -P /content/ -O image.jpg https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQfN_LL8waaCzWlbneQbQQyL2HSPT74j5_l69bM5TvB1lcJI-tjKsP2PI7uSMN3ooXQMko&usqp=CAU\n",
        "# %matplotlib inline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qnsDb8ywsIR",
        "outputId": "41bd2dc1-2445-4ff1-937a-fd2a72f309d9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-03 18:55:31--  https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQfN_LL8waaCzWlbneQbQQyL2HSPT74j5_l69bM5TvB1lcJI-tjKsP2PI7uSMN3ooXQMko\n",
            "Resolving encrypted-tbn0.gstatic.com (encrypted-tbn0.gstatic.com)... 64.233.170.139, 64.233.170.113, 64.233.170.101, ...\n",
            "Connecting to encrypted-tbn0.gstatic.com (encrypted-tbn0.gstatic.com)|64.233.170.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6406 (6.3K) [image/jpeg]\n",
            "Saving to: ‘image.jpg’\n",
            "\n",
            "\r                      0%[                    ]       0  --.-KB/s               \r                    100%[===================>]   6.26K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-03 18:55:31 (72.4 MB/s) - ‘image.jpg’ saved [6406/6406]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загружаем модель для определения ключевых точек лица - понадобится нам для выравнивания\n",
        "import os\n",
        "experiment_type = \"ffhq_encode\"\n",
        "if experiment_type == \"ffhq_encode\" and 'shape_predictor_68_face_landmarks.dat' not in os.listdir():\n",
        "    !wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2  # Скачиваем архив с моделью\n",
        "    !bzip2 -dk shape_predictor_68_face_landmarks.dat.bz2  # Распаковываем архив"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rp4vWdnVVnFS",
        "outputId": "32ee5405-ba1a-451a-c352-689110593123"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-03 18:55:31--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 [following]\n",
            "--2025-02-03 18:55:32--  https://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‘shape_predictor_68_face_landmarks.dat.bz2’\n",
            "\n",
            "shape_predictor_68_ 100%[===================>]  61.07M  11.5MB/s    in 6.5s    \n",
            "\n",
            "2025-02-03 18:55:39 (9.33 MB/s) - ‘shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загружаем сеть-энкодер для получения латентов StyleGAN без выполнения оптимизации для каждого изображения\n",
        "! git clone https://github.com/omertov/encoder4editing.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9vnPdYXQuUl",
        "outputId": "51917dbb-467e-4fd1-979d-b7d5f074c330"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'encoder4editing'...\n",
            "remote: Enumerating objects: 172, done.\u001b[K\n",
            "remote: Counting objects: 100% (78/78), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 172 (delta 49), reused 42 (delta 42), pack-reused 94 (from 1)\u001b[K\n",
            "Receiving objects: 100% (172/172), 33.43 MiB | 15.88 MiB/s, done.\n",
            "Resolving deltas: 100% (59/59), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/encoder4editing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY5y_LmAQuKZ",
        "outputId": "ca868f6a-62ff-43ea-e17f-437b48858aa2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/encoder4editing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Скачаем модель энкодера\n",
        "!gdown 1cUv_reLE6k3604or78EranS7XzuVMWeO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-79vI23Qt_B",
        "outputId": "0c8a3f08-17a4-4ac3-b84c-3a702ae7225b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1cUv_reLE6k3604or78EranS7XzuVMWeO\n",
            "From (redirected): https://drive.google.com/uc?id=1cUv_reLE6k3604or78EranS7XzuVMWeO&confirm=t&uuid=ce4e15ee-f197-4295-872a-c05d76f147db\n",
            "To: /content/encoder4editing/e4e_ffhq_encode.pt\n",
            "100% 1.20G/1.20G [00:24<00:00, 49.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ЗАПУСКАЕМ STREAMLIT"
      ],
      "metadata": {
        "id": "Muaf66RKhQDZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMY1JjVUf6_S",
        "outputId": "dec3c0bb-26ac-4855-b876-b6a0e898ecb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/face_editor.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/face_editor.py\n",
        "import os\n",
        "os.chdir('/content/stylegan2-pytorch')\n",
        "import sys\n",
        "sys.path.append('/content/stylegan2-pytorch')\n",
        "sys.path.append('/content/encoder4editing')\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from model import Generator\n",
        "from torchvision.utils import save_image\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from utils.common import tensor2im\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.optim as optim\n",
        "import math  # Модуль для математических операций\n",
        "from torch.nn import functional as F\n",
        "from torchvision import transforms  # Модуль для преобразования изображений\n",
        "from PIL import Image  # Библиотека для работы с изображениями\n",
        "from tqdm import tqdm\n",
        "\n",
        "os.chdir('/content/encoder4editing')\n",
        "from encoder4editing.models.psp import pSp  # Импортируем модель pSp\n",
        "from argparse import Namespace\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Параметры генератора\n",
        "size = 1024  # Размер изображения\n",
        "latent_dim = 512  # Размер латентного пространства\n",
        "n_mlp = 8  # Количество слоев MLP\n",
        "channel_multiplier = 2\n",
        "ckpt = '/content/stylegan2-pytorch/stylegan2-ffhq-config-f.pt'  # Путь к весам StyleGAN2\n",
        "\n",
        "# Инициализация генератора\n",
        "generator = Generator(size, latent_dim, n_mlp, channel_multiplier=channel_multiplier).to(device)\n",
        "generator.eval()  # Режим валидации\n",
        "checkpoint = torch.load(ckpt)\n",
        "generator.load_state_dict(checkpoint[\"g_ema\"])  # Подгрузка весов\n",
        "\n",
        "# Определяем преобразования для изображения\n",
        "transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),  # Изменяем размер изображения до 256x256\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # Нормализуем значения пикселей\n",
        "])\n",
        "\n",
        "# Загружаем в память предобученную модель энкодера pSp\n",
        "model_path = '/content/encoder4editing/e4e_ffhq_encode.pt'  # Путь к весам энкодера\n",
        "ckpt = torch.load(model_path, map_location='cpu')\n",
        "opts = ckpt['opts']\n",
        "\n",
        "opts['checkpoint_path'] = model_path\n",
        "opts = Namespace(**opts)\n",
        "net = pSp(opts)\n",
        "net.eval()\n",
        "net.to(device)\n",
        "print('Model successfully loaded!')\n",
        "\n",
        "\n",
        "# FACE ALIGNMENT\n",
        "# Определяем тип эксперимента\n",
        "experiment_type = \"ffhq_encode\"\n",
        "\n",
        "# Задаем размер изображения для изменения\n",
        "resize_dims = (256, 256)\n",
        "\n",
        "def run_alignment(image_path):\n",
        "  \"\"\"Выравнивает лицо на изображении, используя dlib.\n",
        "\n",
        "  Args:\n",
        "      image_path: Путь к файлу изображения.\n",
        "\n",
        "  Returns:\n",
        "      Выровненное изображение в формате PIL.Image.\n",
        "  \"\"\"\n",
        "  import dlib\n",
        "  from utils.alignment import align_face  # Функция для выравнивания лица\n",
        "  predictor = dlib.shape_predictor(\"/content/shape_predictor_68_face_landmarks.dat\")\n",
        "  aligned_image = align_face(filepath=image_path, predictor=predictor)\n",
        "  print(\"Aligned image has shape: {}\".format(aligned_image.size))\n",
        "  return aligned_image  # Возвращаем выровненное изображение\n",
        "\n",
        "  # Определяем функцию для отображения результата рядом с исходным\n",
        "def display_alongside_source_image(result_image, source_image):\n",
        "    \"\"\"Отображает результат рядом с исходным изображением.\n",
        "\n",
        "    Args:\n",
        "        result_image: Результирующее изображение (PIL.Image).\n",
        "        source_image: Исходное изображение (PIL.Image).\n",
        "\n",
        "    Returns:\n",
        "        Объединенное изображение (PIL.Image).\n",
        "    \"\"\"\n",
        "    res = np.concatenate([np.array(source_image.resize(resize_dims)),\n",
        "                          np.array(result_image.resize(resize_dims))], axis=1)\n",
        "    return Image.fromarray(res)\n",
        "\n",
        "\n",
        "def run_on_batch(inputs, net):\n",
        "    \"\"\"Запускает модель на пакете данных.\n",
        "\n",
        "    Args:\n",
        "        inputs: Входные данные (тензор PyTorch).\n",
        "        net: Модель pSp.\n",
        "\n",
        "    Returns:\n",
        "        Сгенерированные изображения и латентные векторы.\n",
        "    \"\"\"\n",
        "    images, latents = net(inputs.to(\"cuda\").float(), randomize_noise=False, return_latents=True)  # Запускаем модель\n",
        "    return images, latents\n",
        "\n",
        "# FACE EDITING\n",
        "# Инициализируем редактор латентных векторов\n",
        "from editings import latent_editor\n",
        "\n",
        "editor = latent_editor.LatentEditor(net.decoder, False)\n",
        "\n",
        "# Определяем доступные направления редактирования для InterFaceGAN\n",
        "interfacegan_directions = {\n",
        "    'ffhq_encode': {\n",
        "        'age': 'editings/interfacegan_directions/age.pt',  # Направление для изменения возраста\n",
        "        'smile': 'editings/interfacegan_directions/smile.pt',  # Направление для изменения улыбки\n",
        "        'pose': 'editings/interfacegan_directions/pose.pt'  # Направление для изменения позы\n",
        "    }\n",
        "}\n",
        "\n",
        "available_interfacegan_directions = None\n",
        "\n",
        "available_interfacegan_directions = interfacegan_directions['ffhq_encode']  # Используем направления для \"ffhq_encode\"\n",
        "\n",
        "print(list(available_interfacegan_directions.keys()))  # Выводим список ключей (направлений)\n",
        "\n",
        "# ВОЗРАСТ [-10,10]\n",
        "# As an example, we currently released the age and smile directions for the FFHQ StyleGAN Generator.\n",
        "\n",
        "def change_all(image, age_factor, smile_factor, pose_factor):\n",
        "  \"\"\"Изменяет возраст, улыбку и поворот головы\n",
        "  \"\"\"\n",
        "  if age_factor != 0:\n",
        "    latents = get_latents(image)\n",
        "    interfacegan_direction = torch.load(available_interfacegan_directions[\"age\"]).cuda()\n",
        "    image = editor.apply_interfacegan(latents, interfacegan_direction, factor=age_factor).resize(resize_dims)\n",
        "\n",
        "  if smile_factor != 0:\n",
        "    latents = get_latents(image)\n",
        "    interfacegan_direction = torch.load(available_interfacegan_directions[\"smile\"]).cuda()\n",
        "    image = editor.apply_interfacegan(latents, interfacegan_direction, factor=smile_factor).resize(resize_dims)\n",
        "\n",
        "  if pose_factor != 0:\n",
        "    latents = get_latents(image)\n",
        "    interfacegan_direction = torch.load(available_interfacegan_directions[\"pose\"]).cuda()\n",
        "    image = editor.apply_interfacegan(latents, interfacegan_direction, factor=pose_factor).resize(resize_dims)\n",
        "  return image\n",
        "\n",
        "\n",
        "def change_age(image, age_factor):\n",
        "  \"\"\"Изменяет возраст\n",
        "  \"\"\"\n",
        "  latents = get_latents(image)\n",
        "  interfacegan_direction = torch.load(available_interfacegan_directions[\"age\"]).cuda()\n",
        "  result = editor.apply_interfacegan(latents, interfacegan_direction, factor=age_factor).resize(resize_dims)\n",
        "  return result\n",
        "\n",
        "# SMILE [-10,10]\n",
        "# As an example, we currently released the age and smile directions for the FFHQ StyleGAN Generator.\n",
        "def change_smile(image, smile_factor):\n",
        "  \"\"\"Изменяет улыбку\n",
        "  \"\"\"\n",
        "  latents = get_latents(image)\n",
        "  interfacegan_direction = torch.load(available_interfacegan_directions[\"smile\"]).cuda()\n",
        "  result = editor.apply_interfacegan(latents, interfacegan_direction, factor=smile_factor).resize(resize_dims)\n",
        "  return result\n",
        "\n",
        "# POSE [-10,10]\n",
        "def change_pose(image, pose_factor):\n",
        "  \"\"\"Изменяет поворот головы\n",
        "  \"\"\"\n",
        "  latents = get_latents(image)\n",
        "  interfacegan_direction = torch.load(available_interfacegan_directions[\"pose\"]).cuda()\n",
        "  result = editor.apply_interfacegan(latents, interfacegan_direction, factor=pose_factor).resize(resize_dims)\n",
        "  return result\n",
        "\n",
        "# Выравниваем лицо, если тип эксперимента - кодирование FFHQ\n",
        "def align_resize_image(image):\n",
        "  \"\"\"Выравнивает и изменяет размер изображения для обработки нейросетью\n",
        "  \"\"\"\n",
        "  if experiment_type == \"ffhq_encode\":\n",
        "    input_image = run_alignment(image_path)\n",
        "  else:\n",
        "    input_image = original_image\n",
        "  input_image.resize(resize_dims)\n",
        "  return input_image\n",
        "\n",
        "def get_latents(image):\n",
        "  \"\"\"Получает латентный вектор изображения для редактирования\n",
        "  \"\"\"\n",
        "  image = transform(image)\n",
        "  with torch.no_grad():\n",
        "    images, latents = run_on_batch(image.unsqueeze(0), net)\n",
        "    result_image, latent = images[0], latents[0]  # Извлекаем результат и латентный вектор\n",
        "    return latents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/app.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import base64\n",
        "import face_editor\n",
        "import uuid\n",
        "\n",
        "source_image = Image.open(\"/content/image.jpg\")\n",
        "edited_image = source_image\n",
        "\n",
        "def edit_face():\n",
        "  \"\"\"Редактирует изображение\n",
        "  \"\"\"\n",
        "  global source_image\n",
        "  global edited_image\n",
        "  global age_factor\n",
        "  global smile_factor\n",
        "  global pose_factor\n",
        "  # with st.spinner(text=\"Doing magic...\"):\n",
        "  result_image = face_editor.change_all(source_image, age_factor=age_factor, smile_factor=smile_factor, pose_factor=pose_factor)\n",
        "  edited_image = result_image\n",
        "  col2.image(edited_image)\n",
        "  # col2.download_button(\"Download image\", convert_image(edited_image), \"edited.png\", \"image/png\", key=uuid.uuid4())\n",
        "\n",
        "st.set_page_config(layout=\"wide\", page_title=\"Face Editor\")\n",
        "\n",
        "st.write(\"## Load face image file and play with it!\")\n",
        "st.write(\n",
        "    \"(c) [@Maxim_Kan](https://t.me/Maxim_Kan) [(source)](https://github.com/kleorn/FaceEditor)\"\n",
        ")\n",
        "\n",
        "age_factor = st.slider(\"Age modifier\", -10, 10, 0)\n",
        "smile_factor = st.slider(\"Smile modifier\", -10, 10, 0)\n",
        "pose_factor = st.slider(\"Head turn modifier\", -10, 10, 0)\n",
        "\n",
        "MAX_FILE_SIZE = 5 * 1024 * 1024  # 5MB\n",
        "\n",
        "# Download the fixed image\n",
        "def convert_image(img):\n",
        "    \"\"\"Конвертирует изображение для записи в файл\n",
        "    \"\"\"\n",
        "    buf = BytesIO()\n",
        "    img.save(buf, format=\"PNG\")\n",
        "    byte_im = buf.getvalue()\n",
        "    return byte_im\n",
        "\n",
        "\n",
        "def fix_image(upload):\n",
        "    \"\"\"Загружает изображение для редактирования\n",
        "    \"\"\"\n",
        "    global source_image\n",
        "    global edited_image\n",
        "    source_image = Image.open(upload)\n",
        "    col1.write(\"Original Image :camera:\")\n",
        "    col1.image(source_image)\n",
        "    col1.button('Edit face!', on_click=edit_face)\n",
        "    # edit_face()\n",
        "    col2.write(\"Edited Image :wrench:\")\n",
        "    # col2.image(edited_image)\n",
        "    st.sidebar.markdown(\"\\n\")\n",
        "    return source_image\n",
        "\n",
        "col1, col2 = st.columns(2)\n",
        "my_upload = st.sidebar.file_uploader(\"Upload an image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "if my_upload is not None:\n",
        "    if my_upload.size > MAX_FILE_SIZE:\n",
        "        st.error(\"The uploaded file is too large. Please upload an image smaller than 5MB.\")\n",
        "    else:\n",
        "        source_image = fix_image(upload=my_upload)\n",
        "else:\n",
        "    fix_image(\"/content/image.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X16Rgp-kFPcy",
        "outputId": "2182b89b-41c7-4128-b1a9-a9016f738e71"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Для успешной установки приходится запускать 2 раза, пока не появится строка \"Run `npm audit` for details.\"\n",
        "!npm install localtunnel\n",
        "!npm install localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZIRhiofBF9d",
        "outputId": "f56bc152-c8b0-4de3-e85c-860393877852"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\n",
            "up to date, audited 23 packages in 822ms\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\n",
            "2 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m severity vulnerabilities\n",
            "\n",
            "To address all issues (including breaking changes), run:\n",
            "  npm audit fix --force\n",
            "\n",
            "Run `npm audit` for details.\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K\n",
            "up to date, audited 23 packages in 732ms\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K\n",
            "2 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m severity vulnerabilities\n",
            "\n",
            "To address all issues (including breaking changes), run:\n",
            "  npm audit fix --force\n",
            "\n",
            "Run `npm audit` for details.\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/app.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "cMuGp8gBBY92"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# СКОПИРОВАТЬ IP-адрес, открыть ссылку (не IP!), а IP вставить как пароль\n",
        "print('Скопируйте IP-адрес, откройте ссылку (не IP!), а IP вставьте, как пароль')\n",
        "!npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAgP9H3HBnbb",
        "outputId": "2d610dc4-365b-47c0-b05e-e0a171fb0c32"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Скопируйте IP-адрес, откройте ссылку (не IP!), а IP вставьте, как пароль\n",
            "34.124.229.249\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0Kyour url is: https://major-vans-doubt.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F7djs2yaBxYp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}